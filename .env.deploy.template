# ================================================================================
# SRE Agent Deployment Configuration Template
# ================================================================================
# Copy this file to .env.deploy and fill in your values
# Source before deploying: source .env.deploy && ./deploy.sh

# ================================================================================
# Required Configuration
# ================================================================================

# EKS Cluster
CLUSTER_NAME=

# Docker Images
IMAGE_NAME=
UI_IMAGE_NAME=
IMAGE_TAG=latest

# Monitoring Endpoints (required)
PROMETHEUS_URL=http://prometheus-kube-prometheus-prometheus.observability.svc.cluster.local:9090
ALERTMANAGER_URL=http://prometheus-kube-prometheus-alertmanager.observability.svc.cluster.local:9093

# S3 Bucket for Reports
S3_BUCKET=my-sre-agent-reports-bucket

# Public Base URL (required if using OIDC)
AUTH_PUBLIC_BASE_URL=https://sre-agent.example.com

# ================================================================================
# Optional Configuration
# ================================================================================

# AWS
AWS_REGION=us-east-1
ROLE_NAME=sre-agent-role
S3_PREFIX=sre-agent/reports

# Logs (optional - VictoriaLogs)
LOGS_URL=http://loki-loki-distributed-gateway.observability.svc.cluster.local:80

# Investigation Settings
TIME_WINDOW=1h

# Authentication
ADMIN_INITIAL_USERNAME=admin
AUTH_ALLOWED_DOMAINS=

# ================================================================================
# OIDC/SSO Configuration (optional - all three required if using SSO)
# ================================================================================

OIDC_DISCOVERY_URL=
OIDC_CLIENT_ID=
OIDC_CLIENT_SECRET=

# ================================================================================
# Auto-Generated Secrets (leave empty - generated automatically)
# ================================================================================

AUTH_SESSION_SECRET=
POSTGRES_PASSWORD=
ADMIN_INITIAL_PASSWORD=

# ================================================================================
# NATS JetStream Queue
# ================================================================================

NATS_URL=nats://nats.sre-agent.svc:4222
JETSTREAM_STREAM=SRE_AGENT
JETSTREAM_SUBJECT=sre_agent.alerts
ALERTNAME_ALLOWLIST=CPUThrottlingHigh,KubePodCPUThrottling,CPUThrottling,ContainerCpuThrottled,KubernetesContainerOomKiller,Http5xxRateHigh,Http5xxRateWarning,KubernetesPodNotHealthy,KubernetesPodNotHealthyCritical,RowsRejectedOnIngestion,MemoryPressure

# ================================================================================
# PostgreSQL (in-cluster dev instance)
# ================================================================================

ENABLE_DEV_POSTGRES=1

# ================================================================================
# AWS Secrets Manager
# ================================================================================

ASM_SECRET_NAME=sre-agent
KMS_KEY_ARN=

# ================================================================================
# Deployment Control Flags
# ================================================================================

SKIP_BUILD_PUSH=0
SKIP_BUCKET_CREATE=0
SKIP_BUCKET_POLICY=0
SKIP_ASM_SECRET_CREATE=0
SKIP_IAM_SETUP=0
SKIP_KUBECONFIG_UPDATE=0
DOCKER_TARGET=final

# ================================================================================
# LangSmith Tracing (optional - for LLM observability)
# ================================================================================

LANGSMITH_TRACING=false
LANGSMITH_PROJECT=sre-agent
LANGSMITH_TAGS=production,eks
LANGSMITH_RUN_NAME_PREFIX=sre-agent
LANGSMITH_API_KEY=

# ================================================================================
# LLM Provider Configuration (optional - for AI-enriched investigations)
# ================================================================================

# Enable LLM enrichment (default: false)
LLM_ENABLED=true

# Provider: "vertexai" (Google Cloud) or "anthropic" (Anthropic Claude)
LLM_PROVIDER=anthropic

# Model names:
#   Vertex AI: gemini-2.5-flash, gemini-2.0-pro
#   Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229
LLM_MODEL=claude-sonnet-4-20250514

# LLM Parameters
LLM_TEMPERATURE=0.2
LLM_MAX_OUTPUT_TOKENS=4096
LLM_MOCK=0

# --- Vertex AI Configuration (when LLM_PROVIDER=vertexai) ---
# GCP project and location for Vertex AI + Workload Identity
GOOGLE_CLOUD_PROJECT=my-gcp-project
GOOGLE_CLOUD_LOCATION=us-central1

# GCP Workload Identity Federation (for in-cluster authentication)
GCP_WIF_AUDIENCE=//iam.googleapis.com/projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider
GCP_WIF_CRED_JSON=

# --- Anthropic Configuration (when LLM_PROVIDER=anthropic) ---
# API key from https://console.anthropic.com/
# Extended thinking is always enabled (1024 tokens) - no additional config needed
ANTHROPIC_API_KEY=

# ================================================================================
# Quick Setup Examples
# ================================================================================
#
# Vertex AI:
#   LLM_ENABLED=true
#   LLM_PROVIDER=vertexai
#   LLM_MODEL=gemini-2.5-flash
#   GOOGLE_CLOUD_PROJECT=my-project
#   GOOGLE_CLOUD_LOCATION=us-central1
#   # Workload Identity handles auth
#
# Anthropic Claude:
#   LLM_ENABLED=true
#   LLM_PROVIDER=anthropic
#   LLM_MODEL=claude-3-5-sonnet-20241022
#   ANTHROPIC_API_KEY=sk-ant-api03-...
#   # Extended thinking auto-enabled
#
# No LLM (deterministic only):
#   LLM_ENABLED=false
#   # Smallest image
#
# ================================================================================
