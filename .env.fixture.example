# LLM Configuration for Fixture Capture
# Copy this file to .env.fixture and fill in your actual values
# DO NOT COMMIT .env.fixture (it's in .gitignore)

# Basic LLM settings
LLM_ENABLED=true
LLM_TEMPERATURE=0.2
LLM_MAX_OUTPUT_TOKENS=4096

# ============================================================
# Option 1: Anthropic (Claude)
# ============================================================
LLM_PROVIDER=anthropic
LLM_MODEL=claude-sonnet-4-20250514
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ============================================================
# Option 2: Vertex AI (Gemini)
# ============================================================
# LLM_PROVIDER=vertexai
# LLM_MODEL=gemini-2.5-flash
# GOOGLE_CLOUD_PROJECT=your-gcp-project-id
# GOOGLE_CLOUD_LOCATION=us-central1
# # Note: Vertex AI also requires Application Default Credentials (ADC)
# # Run: gcloud auth application-default login

# ============================================================
# Usage:
# ============================================================
# 1. Install the LLM provider SDK (REQUIRED):
#    For Anthropic:
#      poetry install --extras anthropic
#    For Vertex AI:
#      poetry install --extras vertex
#    For both:
#      poetry install --extras all-providers
#
# 2. Copy this file:
#    cp .env.fixture.example .env.fixture
#
# 3. Edit .env.fixture with your actual API key
#
# 4. Load the configuration:
#    set -a && source .env.fixture && set +a
#
# 5. Run fixture capture with LLM:
#    poetry run python scripts/capture-fixture.py --filter KubeJobFailed --compare-modes
